import re
import sys
import time
from urllib.parse import urlparse, parse_qs
from playwright.sync_api import sync_playwright, Error as PlaywrightError, TimeoutError as PlaywrightTimeoutError

# --- YENÄ° ---
# GÃ¼ncel adresi bulmak iÃ§in kullanÄ±lacak portal adresi
PORTAL_DOMAIN = "https://www.selcuksportshd.is/"

# --- YENÄ° FONKSÄ°YON: GÃœNCEL DOMAIN'Ä° BULMA ---
def find_working_domain(page):
    """
    Portal sayfasÄ±nÄ± ziyaret eder ve 'a.site-button' class'Ä±na sahip
    elementin href Ã¶zelliÄŸinden gÃ¼ncel domain'i Ã§eker.
    """
    print(f"\nğŸ” GÃ¼ncel domain {PORTAL_DOMAIN} adresinden alÄ±nÄ±yor...")
    try:
        page.goto(PORTAL_DOMAIN, timeout=20000, wait_until='domcontentloaded')
        
        # Sizin belirttiÄŸiniz CSS seÃ§ici
        selector = "a.site-button"
        page.wait_for_selector(selector, timeout=10000)
        
        link_element = page.query_selector(selector)
        
        if not link_element:
             print("-> âŒ Portal sayfasÄ±nda 'a.site-button' elementi bulunamadÄ±.")
             return None
        
        domain = link_element.get_attribute('href')
        
        if not domain:
            print("-> âŒ Link elementinde 'href' Ã¶zelliÄŸi bulunamadÄ±.")
            return None

        # Domain'i temizle (sonundaki '/' karakterini kaldÄ±r)
        domain = domain.rstrip('/')
        print(f"âœ… GÃ¼ncel domain baÅŸarÄ±yla bulundu: {domain}")
        return domain
        
    except Exception as e:
        print(f"âŒ Portal sayfasÄ±na ulaÅŸÄ±lamadÄ± veya domain alÄ±namadÄ±: {e.__class__.__name__}")
        return None

# --- GÃœNCELLENEN FONKSÄ°YON: KANAL GRUPLAMA MANTIÄI ---
def get_channel_group(channel_name):
    """
    Verilen kanal ismine gÃ¶re bir grup adÄ± dÃ¶ndÃ¼rÃ¼r.
    """
    channel_name_lower = channel_name.lower()
    group_mappings = {
        'BeinSports': ['bein sports', 'beÄ±n sports'],
        'S Sports': ['s sport'],
        'Tivibu': ['tivibu spor'],
        'Ulusal Kanallar': ['a spor', 'trt spor', 'trt 1'],
        'DiÄŸer Spor': ['smart spor', 'nba tv', 'eurosport'],
        'Belgesel': ['national geographic', 'nat geo', 'discovery', 'dmax', 'bbc earth', 'history'],
        'Film & Dizi': ['bein series', 'bein movies', 'movie smart']
    }
    for group, keywords in group_mappings.items():
        for keyword in keywords:
            if keyword in channel_name_lower:
                return group
    return "MaÃ§ YayÄ±nlarÄ±"

# --- GÃœNCELLENEN FONKSÄ°YON: ARTIK DOMAIN PARAMETRESÄ° ALIYOR ---
def scrape_channel_links(page, domain_to_scrape):
    """
    SelÃ§uk Sports ana sayfasÄ±nÄ± ziyaret eder ve tÃ¼m kanallarÄ±
    isim, URL ve grup bilgisiyle birlikte toplar.
    """
    print(f"\nğŸ“¡ Kanallar {domain_to_scrape} adresinden Ã§ekiliyor...")
    channels = []
    try:
        page.goto(domain_to_scrape, timeout=25000, wait_until='domcontentloaded')
        
        link_elements = page.query_selector_all("a[data-url]")
        
        if not link_elements:
            print("âŒ Ana sayfada 'data-url' iÃ§eren hiÃ§bir kanal linki bulunamadÄ±.")
            return []
            
        for link in link_elements:
            player_url = link.get_attribute('data-url')
            name_element = link.query_selector('div.name')
            
            if name_element and player_url:
                channel_name = name_element.inner_text().strip()
                
                # --- GÃœNCELLENDÄ°: Global deÄŸiÅŸken yerine parametreyi kullan ---
                if player_url.startswith('/'):
                    base_domain = domain_to_scrape.rstrip('/')
                    player_url = f"{base_domain}{player_url}"
                
                group_name = get_channel_group(channel_name)
                
                channels.append({
                    'name': channel_name,
                    'url': player_url,
                    'group': group_name
                })

        print(f"âœ… {len(channels)} adet potansiyel kanal linki bulundu ve gruplandÄ±rÄ±ldÄ±.")
        return channels
        
    except PlaywrightError as e:
        print(f"âŒ SelÃ§uk Sports ana sayfasÄ±na ulaÅŸÄ±lamadÄ±. Hata: {e.__class__.__name__}")
        return []

def extract_m3u8_from_page(page, player_url):
    """
    OynatÄ±cÄ± sayfasÄ±ndan M3U8 linkini doÄŸrudan oluÅŸturur.
    """
    try:
        page.goto(player_url, timeout=20000, wait_until="domcontentloaded")
        content = page.content()
        base_url_match = re.search(r"this\.baseStreamUrl\s*=\s*['\"](https?://.*?)['\"]", content)
        if not base_url_match:
            print(" -> âŒ 'baseStreamUrl' bulunamadÄ±.", end="")
            return None
        base_url = base_url_match.group(1)
        
        parsed_url = urlparse(player_url)
        query_params = parse_qs(parsed_url.query)
        stream_id = query_params.get('id', [None])[0]
        if not stream_id:
            print(" -> âŒ 'id' parametresi bulunamadÄ±.", end="")
            return None

        m3u8_link = f"{base_url}{stream_id}/playlist.m3u8"
        return m3u8_link

    except Exception:
        print(" -> âŒ Sayfa yÃ¼klenirken hata oluÅŸtu.", end="")
        return None

# --- GÃœNCELLENEN MAIN FONKSÄ°YONU ---
def main():
    with sync_playwright() as p:
        print("ğŸš€ Playwright ile SelÃ§uk Sports M3U8 Kanal Ä°ndirici BaÅŸlatÄ±lÄ±yor...")
        
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'
        )
        page = context.new_page()

        # --- YENÄ° ADIM: Ã–NCE GÃœNCEL DOMAIN'Ä° BUL ---
        selcuksports_domain = find_working_domain(page)

        if not selcuksports_domain:
            print("âŒ UYARI: GÃ¼ncel domain portal sayfasÄ±ndan alÄ±namadÄ±. Ä°ÅŸlem sonlandÄ±rÄ±lÄ±yor.")
            browser.close()
            sys.exit(1)
        # --- BÄ°TTÄ° ---

        # --- GÃœNCELLENDÄ°: Bulunan domain'i fonksiyona parametre olarak ver ---
        channels = scrape_channel_links(page, selcuksports_domain)

        if not channels:
            print("âŒ UYARI: HiÃ§bir kanal bulunamadÄ±, iÅŸlem sonlandÄ±rÄ±lÄ±yor.")
            browser.close()
            sys.exit(1)
        
        m3u_content = []
        output_filename = "selcuksports_kanallar.m3u8"
        print(f"\nğŸ“º {len(channels)} kanal iÃ§in M3U8 linkleri iÅŸleniyor...")
        created = 0
        
        for i, channel_info in enumerate(channels, 1):
            channel_name = channel_info['name']
            player_url = channel_info['url']
            group_name = channel_info['group']
            
            print(f"[{i}/{len(channels)}] {channel_name} (Grup: {group_name}) iÅŸleniyor...", end="")
            
            m3u8_link = extract_m3u8_from_page(page, player_url)
            
            if m3u8_link:
                print(" -> âœ… Link bulundu.")
                m3u_content.append(f'#EXTINF:-1 tvg-name="{channel_name}" group-title="{group_name}",{channel_name}')
                m3u_content.append(m3u8_link)
                created += 1
            else:
                print(" -> âŒ Link bulunamadÄ±.")
        
        browser.close()

        if created > 0:
            header = "#EXTM3U"
            with open(output_filename, "w", encoding="utf-8") as f:
                f.write(header + "\n") 
                f.write("\n".join(m3u_content))
            print(f"\n\nğŸ“‚ {created} kanal baÅŸarÄ±yla '{output_filename}' dosyasÄ±na kaydedildi.")
        else:
            print("\n\nâ„¹ï¸  GeÃ§erli hiÃ§bir M3U8 linki bulunamadÄ±ÄŸÄ± iÃ§in dosya oluÅŸturulmadÄ±.")

        print("\n" + "="*50)
        print("ğŸ“Š Ä°ÅLEM SONUCLARI")
        print("="*50)
        print(f"âœ… BaÅŸarÄ±yla oluÅŸturulan link: {created}")
        print(f"âŒ BaÅŸarÄ±sÄ±z veya atlanan kanal: {len(channels) - created}")
        print("\nğŸ‰ Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±!")

if __name__ == "__main__":
    main()
